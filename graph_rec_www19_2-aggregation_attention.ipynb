{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86a7ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 29 13:16:16 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:17:00.0 Off |                  N/A |\r\n",
      "|  0%   39C    P8    16W / 350W |   1481MiB / 24268MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |\r\n",
      "| 30%   49C    P0    99W / 350W |      0MiB / 24268MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A    362546      C   ...raph-embedding/bin/python     1479MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b186866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict\n",
    "#from UV_Encoders import UV_Encoder\n",
    "#from UV_Aggregators import UV_Aggregator\n",
    "#from Social_Encoders import Social_Encoder\n",
    "#from Social_Aggregators import Social_Aggregator\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "import datetime\n",
    "import argparse\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "006ecf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "use_cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "embed_dim = 128\n",
    "dir_data = './data/toy_dataset'\n",
    "\n",
    "path_data = dir_data + \".pickle\"\n",
    "data_file = open(path_data, 'rb')\n",
    "history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, train_u, train_v, train_r, test_u, test_v, test_r, social_adj_lists, ratings_list = pickle.load(\n",
    "    data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6155488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.TensorDataset(torch.LongTensor(train_u), torch.LongTensor(train_v),\n",
    "                                              torch.FloatTensor(train_r))\n",
    "testset = torch.utils.data.TensorDataset(torch.LongTensor(test_u), torch.LongTensor(test_v),\n",
    "                                         torch.FloatTensor(test_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bcc99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "test_batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "# 705명 유저\n",
    "num_users = history_u_lists.__len__()\n",
    "\n",
    "# 1941개 아이템 수 \n",
    "num_items = history_v_lists.__len__()\n",
    "\n",
    "# 8등급, 2.0: 0, 1.0: 1, 3.0: 2, 4.0: 3, 2.5: 4, 3.5: 5, 1.5: 6, 0.5: 7\n",
    "num_ratings = ratings_list.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a2bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_dim = 128차원 \n",
    "\n",
    "u2e = nn.Embedding(num_users, embed_dim).to(device)\n",
    "v2e = nn.Embedding(num_items, embed_dim).to(device)\n",
    "r2e = nn.Embedding(num_ratings, embed_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a05b811f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(705, 128), Embedding(1941, 128), Embedding(8, 128))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u2e, v2e, r2e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76f0cd",
   "metadata": {},
   "source": [
    "### 처음 시작하는 부분 노드 128개 시작 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ef5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "    batch_nodes_u, batch_nodes_v, labels_list = data\n",
    "    #optimizer.zero_grad()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7127eba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([595, 327, 318, 699, 139, 689,  43, 231, 110, 375, 637,  85, 447,  23,\n",
       "         256, 380, 509, 515, 614, 300,  39, 626, 642, 104, 681, 316,  76, 496,\n",
       "         382, 498,  23, 336, 490, 673, 688, 674, 211, 665,  38, 428, 458, 579,\n",
       "         296, 546, 225, 296, 192, 262, 315, 225, 257, 225,  80,  75, 216, 225,\n",
       "         461, 607, 276, 499, 408, 180, 360, 392, 288,  83, 196, 459, 425, 447,\n",
       "         143,  82, 198,  88, 124, 193, 463, 440,   8, 428, 321, 514, 503, 459,\n",
       "         216, 398,  53, 377, 666, 533,   9, 430,  58, 259, 689, 116, 155,  99,\n",
       "         183, 324, 147, 703, 509, 228,  58, 451, 262,  53, 444, 374, 424, 296,\n",
       "         267, 620,   2, 573, 248, 325,  74,  88, 258, 637, 625,  53, 146, 700,\n",
       "         508, 493]),\n",
       " tensor([  68,   74,   86,   74,   31,   76,  661,  132,   26,   47, 1472,   32,\n",
       "           78,  726, 1526,  673,    6,   90,  120,   72,   73, 1282,   68,   72,\n",
       "          267,   32,   17,    0,   86,   34,  383,  120,  333,   39,   11,  102,\n",
       "          296,   47,  997,   76,   52,   67,   24,   55,  200,   76,   62, 1644,\n",
       "           31,  890,   20, 1203,  122, 1000,   33, 1400,   62,   32,   61,  144,\n",
       "           23,   24,   69,   60,   57, 1893,   51, 1105,   42,   55,  979,   46,\n",
       "           47, 1486,   58,  700,   64,  396,   55,   62,  677,   27,   61,  768,\n",
       "           72,   39,    2,   32,   21,   31,   47,   18,   74,   60,  102,   24,\n",
       "          211,    6,   47,   24, 1335,   47,   47,   69,  718,   62,  444,  844,\n",
       "           57,   57,   45,   31,   17, 1080,  102,   52,   24,  102,  162,  767,\n",
       "           24,   21,  282,  230,   47,  125,  125,   51]),\n",
       " tensor([2.5000, 2.5000, 3.0000, 2.5000, 3.0000, 3.0000, 2.0000, 3.0000, 2.0000,\n",
       "         3.0000, 4.0000, 0.5000, 3.0000, 3.5000, 1.0000, 4.0000, 4.0000, 2.5000,\n",
       "         3.0000, 3.0000, 4.0000, 1.5000, 4.0000, 3.5000, 3.0000, 4.0000, 3.5000,\n",
       "         1.5000, 2.5000, 3.0000, 3.0000, 4.0000, 3.0000, 2.0000, 4.0000, 3.0000,\n",
       "         3.0000, 4.0000, 2.5000, 3.0000, 2.0000, 3.5000, 3.5000, 3.5000, 1.5000,\n",
       "         1.0000, 3.5000, 3.5000, 3.0000, 2.5000, 3.5000, 2.5000, 2.0000, 4.0000,\n",
       "         4.0000, 2.5000, 3.5000, 1.0000, 2.5000, 3.5000, 1.0000, 3.0000, 3.0000,\n",
       "         3.0000, 3.5000, 3.5000, 3.0000, 3.5000, 3.0000, 4.0000, 3.0000, 1.0000,\n",
       "         2.5000, 4.0000, 4.0000, 3.0000, 4.0000, 0.5000, 3.5000, 4.0000, 3.5000,\n",
       "         3.5000, 2.0000, 3.0000, 3.5000, 4.0000, 2.5000, 1.0000, 3.5000, 3.5000,\n",
       "         3.0000, 1.0000, 3.0000, 2.0000, 3.0000, 4.0000, 1.5000, 2.5000, 4.0000,\n",
       "         3.5000, 2.5000, 1.0000, 3.0000, 3.0000, 3.0000, 2.0000, 4.0000, 2.5000,\n",
       "         0.5000, 4.0000, 3.5000, 2.0000, 2.5000, 4.0000, 2.0000, 3.0000, 3.5000,\n",
       "         2.5000, 2.5000, 3.0000, 4.0000, 4.0000, 4.0000, 1.5000, 4.0000, 4.0000,\n",
       "         2.5000, 4.0000]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_nodes_u, batch_nodes_v, labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81bd61",
   "metadata": {},
   "source": [
    "### UV_Encoder 들어가는 부분 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "becd55ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5ce30df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_history_uv = []\n",
    "tmp_history_r = []\n",
    "for node in batch_nodes_u:\n",
    "    tmp_history_uv.append(history_u_lists[int(node)])\n",
    "    tmp_history_r.append(history_ur_lists[int(node)])\n",
    "\n",
    "len(tmp_history_uv), len(tmp_history_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c090caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, embedding_dims):\n",
    "        super(Attention, self).__init__()\n",
    "        self.embed_dim = embedding_dims\n",
    "        self.bilinear = nn.Bilinear(self.embed_dim, self.embed_dim, 1)\n",
    "        self.att1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
    "        self.att2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.att3 = nn.Linear(self.embed_dim, 1)\n",
    "        self.softmax = nn.Softmax(0)\n",
    "\n",
    "    def forward(self, node1, u_rep, num_neighs):\n",
    "        uv_reps = u_rep.repeat(num_neighs, 1)\n",
    "        x = torch.cat((node1, uv_reps), 1)\n",
    "        x = F.relu(self.att1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.att2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.att3(x)\n",
    "        att = F.softmax(x, dim=0)\n",
    "        return att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98f44d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "uv = True\n",
    "# neigh_feats = self.aggregator.forward(nodes, tmp_history_uv, tmp_history_r)  # user-item network \n",
    "# 위에 부분을 사용한 것. \n",
    "'''\n",
    "\n",
    "neigh_feats = agg_u_history.forward(batch_nodes_u, tmp_history_uv, tmp_history_r)\n",
    "\n",
    "'''\n",
    "\n",
    "embed_dim = 128\n",
    "device = 'cpu'\n",
    "\n",
    "# 초기화 해주기 위한 빈 torch \n",
    "embed_matrix = torch.empty(len(tmp_history_uv), embed_dim, dtype=torch.float).to(device)\n",
    "#print(embed_matrix.shape)\n",
    "\n",
    "w_r1 = nn.Linear(embed_dim * 2, embed_dim).to(device)\n",
    "w_r2 = nn.Linear(embed_dim, embed_dim).to(device)\n",
    "#att = Attention(embed_dim)\n",
    "\n",
    "att = Attention(embed_dim)\n",
    "\n",
    "for i in range(len(tmp_history_uv)): \n",
    "    history = tmp_history_uv[i]\n",
    "    num_histroy_item = len(history) # i = 0일때, 10개 \n",
    "    tmp_label = tmp_history_r[i]\n",
    "    \n",
    "    if uv == True:\n",
    "        # user component\n",
    "        e_uv = v2e.weight[history].to(device)\n",
    "        uv_rep = u2e.weight[batch_nodes_u[i]].to(device) # i = 0일때, torch.Size([128])\n",
    "    else:\n",
    "        # item component\n",
    "        e_uv = u2e.weight[history].to(deivce)\n",
    "        uv_rep = v2e.weight[batch_nodes_u[i]].to(device)\n",
    "\n",
    "    e_r = r2e.weight[tmp_label].to(device)\n",
    "    x = torch.cat((e_uv, e_r), 1)\n",
    "    #x = x.to('cpu') ## 제거 가능 \n",
    "    \n",
    "    x = F.relu(w_r1(x))\n",
    "    o_history = F.relu(w_r2(x)).to(device) # i = 0일때, torch.Size([10, 128])\n",
    "\n",
    "    # attention 함수 실행 부분 \n",
    "    att_w = att(o_history, uv_rep, num_histroy_item) # i = 0일때, (torch.Size([10, 128]), torch.Size([128]), 10) ---> torch.Size([10, 1])\n",
    "    att_history = torch.mm(o_history.t(), att_w) # torch.Size([128, 1])\n",
    "    att_history = att_history.t() # torch.Size([1, 128])\n",
    "\n",
    "    embed_matrix[i] = att_history # torch.Size([128, 128])\n",
    "    \n",
    "to_feats = embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb71a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15598685",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(2 * embed_dim, embed_dim) \n",
    "neigh_feats = to_feats.to(device)\n",
    "\n",
    "self_feats = u2e.weight[batch_nodes_u].to(device)\n",
    "\n",
    "combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
    "combined = F.relu(linear1(combined)) # torch.Size([128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d500e96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1891, 0.0242,  ..., 0.3887, 0.1054, 0.0823],\n",
       "        [0.0000, 0.0206, 0.0000,  ..., 0.0993, 0.0000, 0.0134],\n",
       "        [0.0000, 0.3735, 0.0000,  ..., 0.2190, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.2187,  ..., 0.8151, 0.0480, 0.0332],\n",
       "        [0.6975, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2481],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3918, 0.0000]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf8e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
